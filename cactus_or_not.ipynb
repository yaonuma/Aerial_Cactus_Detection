{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":45,"outputs":[{"output_type":"stream","text":"/kaggle/input/aerial-cactus-identification/train.csv\n/kaggle/input/aerial-cactus-identification/test.zip\n/kaggle/input/aerial-cactus-identification/train.zip\n/kaggle/input/aerial-cactus-identification/sample_submission.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Import the necessary libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import glob\nimport os\nimport shutil\nimport zipfile\n\nimport pandas as pd\nimport pkg_resources\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n\nTERMCOLOR = True\nif TERMCOLOR:\n    from termcolor import colored\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('max_colwidth', 500)\npd.set_option('display.width', 10000)","execution_count":47,"outputs":[{"output_type":"stream","text":"Num GPUs Available:  1\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"A function to list the packages and versions installed in the environment"},{"metadata":{"trusted":true},"cell_type":"code","source":"def list_packages_versions():\n    installed_packages = pkg_resources.working_set\n    installed_packages_list = sorted([\"%s==%s\" % (i.key, i.version) for i in installed_packages])\n    for item in installed_packages_list:\n        print(item)\n    print('\\n')\n    return\n","execution_count":84,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A function that converts the raw directory structure into one that is compatible with ImageDataGenerator, a Keras class that facilitates easy train/validation/test data preprocessing."},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_raw2ImageDataGenerator(path):\n    \n    if not os.path.exists(path + 'data'):\n        os.makedirs(path+'data')\n        \n    if not os.path.exists(path + 'train.csv'):\n        shutil.copyfile('/kaggle/input/aerial-cactus-identification/train.csv', path + 'train.csv')\n    if not os.path.exists(path + 'test.zip'):\n        shutil.copyfile('/kaggle/input/aerial-cactus-identification/test.zip', path + 'test.zip')\n    if not os.path.exists(path + 'train.zip'):\n        shutil.copyfile('/kaggle/input/aerial-cactus-identification/train.zip', path + 'train.zip')\n    if not os.path.exists(path + 'sample_submissoin.csv'):\n        shutil.copyfile('/kaggle/input/aerial-cactus-identification/sample_submission.csv', path + 'sample_submission.csv')\n    \n    with zipfile.ZipFile(path+'train.zip', 'r') as zip_ref:\n        zip_ref.extractall(path)\n    with zipfile.ZipFile(path+'test.zip', 'r') as zip_ref:\n        zip_ref.extractall(path)\n        \n    if not os.path.exists(path+'test/no_label'):    \n        os.makedirs(path+'test/no_label')\n    source_dir = path+'test'\n    target_dir = path+'test/no_label'\n    file_names = os.listdir(source_dir)\n\n    for file_name in file_names:\n        try:\n            shutil.move(os.path.join(source_dir, file_name), target_dir)\n        except shutil.Error:\n            pass\n    \n    # create a dictionary of image labels. it is best to cache this information now to avoid an N^2 image sorting\n    # algorithm. Now it is 2*N. Much better\n    label_dict = {}\n    with open(path + 'train.csv', 'r') as a_file:\n        for line in a_file:\n            pair = line.split(',')\n            if pair[1].rstrip() == '0':\n                label = 'not_has_cactus'\n            else:\n                label = 'has_cactus'\n            label_dict[pair[0]] = label\n    a_file.close()\n\n    # create the flow_from_directory folders\n    if not os.path.exists(path + '/train/has_cactus'):\n        os.makedirs(path + '/train/has_cactus')\n    if not os.path.exists(path + '/train/not_has_cactus'):\n        os.makedirs(path + '/train/not_has_cactus')\n    if not os.path.exists(path + '/submissions'):\n        os.makedirs(path + '/submissions')\n\n    # go through each image in the original folder and look up its placement in the dictionary\n    for image in glob.glob(path + '/train/*.jpg'):\n        image = image.split('/')[-1]\n        shutil.move(path + 'train/' + image, path + '/train/' + label_dict[image] + '/' + image)\n      \n\n    return","execution_count":113,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The 2DConvNet. A simple model implemented from scratch."},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(data_root_path):\n    DESIRED_ACCURACY = 0.99\n\n    class myCallback(tf.keras.callbacks.Callback):\n        def on_epoch_end(self, epoch, logs={}):\n            if logs.get('accuracy') >= DESIRED_ACCURACY:  # this is the stopping criterion for the training\n                print(\"\\nReached \" + str(DESIRED_ACCURACY * 100) + \"% accuracy so cancelling training!\")\n                self.model.stop_training = True\n\n    callbacks = myCallback()\n\n    model = tf.keras.models.Sequential([\n        # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n        # This is the first convolution\n        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        # The second convolution\n        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        # The third convolution\n        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        # # The fourth convolution\n        # tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n        # tf.keras.layers.MaxPooling2D(2, 2),\n        # # The fifth convolution\n        # tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n        # tf.keras.layers.MaxPooling2D(2, 2),\n        # Flatten the results to feed into a DNN\n        tf.keras.layers.Flatten(),\n        # 512 neuron hidden layer\n        tf.keras.layers.Dense(512, activation='relu'),\n        # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    print(model.summary())\n\n    model.compile(loss='binary_crossentropy',\n                  optimizer=RMSprop(lr=0.001),\n                  metrics=['accuracy'])\n\n    # This code block should create an instance of an ImageDataGenerator called train_datagen\n    # And a train_generator by calling train_datagen.flow_from_directory\n    train_datagen = ImageDataGenerator(featurewise_center=True,\n                                       featurewise_std_normalization=True,\n                                       rotation_range=40,\n                                       width_shift_range=0.2,\n                                       zoom_range=0.2,\n                                       horizontal_flip=True,\n                                       rescale=1 / 255,\n                                       validation_split=0.2)\n\n    # Flow training images in batches of 128 using train_datagen generator\n    train_generator = train_datagen.flow_from_directory(data_root_path + 'train',\n                                                        subset='training',\n                                                        target_size=(32, 32),\n                                                        batch_size=128,\n                                                        class_mode='binary')\n    validation_generator = train_datagen.flow_from_directory(data_root_path + 'train',\n                                                             subset='validation',\n                                                             target_size=(32, 32),\n                                                             batch_size=128,\n                                                             class_mode='binary')\n\n    # model fitting\n    history = model.fit_generator(\n        train_generator,\n        validation_data=validation_generator,\n        validation_steps=20,\n        steps_per_epoch=20,\n        epochs=100,\n        verbose=1,\n        callbacks=[callbacks]\n    )\n\n    # summarize history for accuracy and loss\n    plt.figure(figsize=(6, 4))\n    plt.plot(history.history['accuracy'], \"g--\", label=\"Accuracy of training data\")\n    plt.plot(history.history['val_accuracy'], \"g\", label=\"Accuracy of validation data\")\n    plt.plot(history.history['loss'], \"r--\", label=\"Loss of training data\")\n    plt.plot(history.history['val_loss'], \"r\", label=\"Loss of validation data\")\n    plt.title('Model Accuracy and Loss')\n    plt.ylabel('Accuracy and Loss')\n    plt.xlabel('Training Epoch')\n    plt.ylim(0)\n    plt.legend()\n    plt.show()\n\n    return model","execution_count":111,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A function to evaluate the trained model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model(data_root_path, model):\n    test_datagen = ImageDataGenerator(featurewise_center=True,\n                                      featurewise_std_normalization=True,\n                                      rotation_range=40,\n                                      width_shift_range=0.2,\n                                      zoom_range=0.2,\n                                      horizontal_flip=True,\n                                      rescale=1 / 255)\n\n    test_generator = test_datagen.flow_from_directory(data_root_path + '/test/',\n                                                      target_size=(32, 32),\n                                                      batch_size=16,\n                                                      class_mode=None,  # only data, no labels\n                                                      shuffle=False)\n\n    probabilities = model.predict_generator(test_generator)\n\n    return probabilities\n","execution_count":66,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A function to write the submission file."},{"metadata":{"trusted":true},"cell_type":"code","source":"def write_submission(raw_data_path, probs):\n    test_result_dict = {}\n\n    for i, image in enumerate(glob.glob(raw_data_path + 'test/no_label/*.jpg')):\n        image = image.split('/')[-1]\n        test_result_dict[image] = probs[i][0]\n\n    df_submission = pd.read_csv(raw_data_path + 'sample_submission.csv')\n\n    def result_fill(x):\n        return test_result_dict[x[0]]\n\n    df_submission['has_cactus'] = df_submission.apply(result_fill, axis=1)\n    df_submission.sort_values(by=['id']).to_csv(raw_data_path + 'submissions/submission.csv')\n\n    return","execution_count":52,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Driver code:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# look at versions to avoid confusion with deprecation/compatibility\nlist_packages_versions()","execution_count":53,"outputs":[{"output_type":"stream","text":"absl-py==0.11.0\nadal==1.2.2\naffine==2.3.0\naiobotocore==1.1.2\naiohttp-cors==0.7.0\naiohttp==3.7.2\naioitertools==0.7.1\naioredis==1.3.1\nalabaster==0.7.12\nalbumentations==0.5.1\nalembic==1.4.3\nallennlp==1.2.1\naltair==4.1.0\nanaconda-client==1.7.2\nanaconda-project==0.8.3\nannoy==1.17.0\nansiwrap==0.8.4\nappdirs==1.4.3\nargh==0.26.2\narrow==0.15.5\narviz==0.10.0\nasn1crypto==1.3.0\nastroid==2.3.3\nastropy==4.0.1.post1\nastunparse==1.6.3\nasync-generator==1.10\nasync-timeout==3.0.1\natomicwrites==1.3.0\nattrs==19.3.0\naudioread==2.1.9\nautopep8==1.5.1\nbabel==2.8.0\nbackcall==0.1.0\nbackports.shutil-get-terminal-size==1.0.0\nbaker==1.3\nbasemap==1.2.1\nbayesian-optimization==1.2.0\nbayespy==0.5.20\nbcolz==1.2.1\nbeautifulsoup4==4.9.0\nbinaryornot==0.4.4\nbiopython==1.78\nbitarray==1.2.1\nbkcharts==0.2\nblack==19.10b0\nbleach==3.1.4\nblessings==1.7\nblinker==1.4\nblis==0.4.1\nbokeh==2.2.3\nboruta==0.3\nboto3==1.16.19\nboto==2.49.0\nbotocore==1.19.19\nbottleneck==1.3.2\nbq-helper==0.4.1\nbqplot==0.12.19\nbranca==0.4.1\nbrewer2mpl==1.4.1\nbrotlipy==0.7.0\ncachetools==3.1.1\ncairocffi==1.2.0\ncairosvg==2.5.0\ncartopy==0.17.0\ncatalogue==1.0.0\ncatalyst==20.11\ncatboost==0.24.2\ncategory-encoders==2.2.2\ncertifi==2020.11.8\ncesium==0.9.12\ncffi==1.14.0\ncftime==1.2.1\nchainer-chemistry==0.7.1\nchainer==7.7.0\nchainercv==0.13.1\nchardet==3.0.4\ncleverhans==3.0.1\nclick-plugins==1.1.1\nclick==7.1.1\ncliff==3.5.0\ncligj==0.7.0\ncloud-tpu-client==0.10\ncloudpickle==1.6.0\nclyent==1.2.2\ncmaes==0.7.0\ncmd2==1.4.0\ncmdstanpy==0.9.5\ncmudict==0.4.5\ncolorama==0.4.3\ncolorcet==2.0.2\ncolorful==0.5.4\ncolorlog==4.6.2\ncolorlover==0.3.0\nconda-package-handling==1.6.0\nconda==4.9.2\nconfigargparse==1.2.3\nconfigparser==5.0.1\nconfuse==1.1.0\ncontextily==1.0.1\ncontextlib2==0.6.0.post1\nconvertdate==2.3.0\nconx==3.7.10\ncookiecutter==1.7.0\ncoverage==5.3\ncryptography==2.8\ncssselect2==0.4.1\ncudf==0.16.0\ncufflinks==0.17.3\ncuml==0.16.0\ncupy-cuda102==8.1.0\ncupy==8.1.0\ncvxcanon==0.1.2\ncvxpy==1.1.7\ncycler==0.10.0\ncymem==2.0.4\ncysignals==1.10.2\ncython==0.29.21\ncytoolz==0.10.1\ndask-cudf==0.16.0\ndask-glm==0.2.0\ndask-ml==1.7.0\ndask-xgboost==0.1.11\ndask==2.30.0\ndatashader==0.11.1\ndatashape==0.5.2\ndeap==1.3.1\ndecorator==4.4.2\ndeepdish==0.3.6\ndefusedxml==0.6.0\ndelorean==1.0.0\ndeprecated==1.2.10\ndeprecation==2.1.0\ndescartes==1.1.0\ndiff-match-patch==20181111\ndill==0.3.3\ndipy==1.3.0\ndistributed==2.30.1\ndlib==19.21.0\ndm-tree==0.1.5\ndocker-pycreds==0.4.0\ndocker==4.2.0\ndocopt==0.6.2\ndocutils==0.15.2\nearthengine-api==0.1.242\neasydev==0.10.1\necos==2.0.7.post1\neli5==0.10.1\nemoji==0.6.0\nen-core-web-lg==2.3.1\nen-core-web-sm==2.3.1\nentrypoints==0.3\nephem==3.7.7.1\nessentia==2.1b6.dev234\net-xmlfile==1.0.1\nfancyimpute==0.5.5\nfastai==2.0.19\nfastavro==1.1.0\nfastcache==1.1.0\nfastcore==1.3.2\nfastprogress==1.0.0\nfastrlock==0.5\nfasttext==0.9.2\nfbpca==1.0\nfbprophet==0.7.1\nfeather-format==0.4.1\nfeaturetools==0.21.0\nfilelock==3.0.10\nfiona==1.8.6\nfitter==1.3.0\nflake8==3.7.9\nflashtext==2.7\nflask==1.1.2\nfolium==0.11.0\nfsspec==0.8.4\nfuncy==1.15\nfury==0.6.1\nfuture==0.18.2\nfuzzywuzzy==0.18.0\ngast==0.3.3\ngatspy==0.3\ngcsfs==0.6.1\ngdal==2.4.1\ngensim==3.8.3\ngeographiclib==1.50\ngeohash==1.0\ngeojson==2.5.0\ngeopandas==0.8.1\ngeoplot==0.4.1\ngeopy==2.0.0\ngeoviews==1.8.1\ngevent==1.5.0\nggplot==0.11.5\ngitdb==4.0.4\ngitpython==3.1.1\nglob2==0.7\ngluoncv==0.8.0\ngluonnlp==0.10.0\ngmpy2==2.1.0b1\ngoogle-api-core==1.23.0\ngoogle-api-python-client==1.8.0\ngoogle-auth-httplib2==0.0.3\ngoogle-auth-oauthlib==0.4.1\ngoogle-auth==1.14.0\ngoogle-cloud-automl==1.0.1\ngoogle-cloud-bigquery==1.12.1\ngoogle-cloud-bigtable==1.2.1\ngoogle-cloud-core==1.3.0\ngoogle-cloud-dataproc==0.7.0\ngoogle-cloud-datastore==1.12.0\ngoogle-cloud-firestore==1.6.2\ngoogle-cloud-kms==1.4.0\ngoogle-cloud-language==1.3.0\ngoogle-cloud-logging==1.15.0\ngoogle-cloud-pubsub==1.4.3\ngoogle-cloud-scheduler==1.2.1\ngoogle-cloud-spanner==1.15.1\ngoogle-cloud-speech==1.3.2\ngoogle-cloud-storage==1.27.0\ngoogle-cloud-tasks==1.5.0\ngoogle-cloud-translate==2.0.1\ngoogle-cloud-videointelligence==1.14.0\ngoogle-cloud-vision==1.0.0\ngoogle-pasta==0.2.0\ngoogle-resumable-media==0.5.0\ngoogle==3.0.0\ngoogleapis-common-protos==1.52.0\ngplearn==0.4.1\ngpustat==0.6.0\ngpxpy==1.4.2\ngraphviz==0.8.4\ngreenlet==0.4.15\ngrpc-google-iam-v1==0.12.3\ngrpcio-gcp==0.2.2\ngrpcio==1.33.2\ngym==0.17.3\nh2o==3.30.1.3\nh5py==2.10.0\nhaversine==2.3.0\nheamy==0.0.7\nheapdict==1.0.1\nhep-ml==0.6.1\nhiredis==1.1.0\nhmmlearn==0.2.4\nholidays==0.10.3\nholoviews==1.13.5\nhpsklearn==0.1.0\nhtml5lib==1.0.1\nhtmlmin==0.1.12\nhttplib2==0.17.2\nhttplib2shim==0.0.3\nhumanize==3.1.0\nhunspell==0.5.5\nhusl==4.0.3\nhyperopt==0.2.5\nhypertools==0.6.3\nhypothesis==5.10.0\nibis-framework==1.4.0\nidna==2.9\nimagecodecs==2020.5.30\nimagehash==4.1.0\nimageio==2.8.0\nimagesize==1.2.0\nimbalanced-learn==0.7.0\nimgaug==0.4.0\nimplicit==0.4.4\nimportlib-metadata==1.6.0\nintervaltree==3.0.2\nipykernel==5.1.1\nipython-genutils==0.2.0\nipython-sql==0.3.9\nipython==7.13.0\nipywidgets==7.5.1\niso3166==1.0.1\nisort==4.3.21\nisoweek==1.3.3\nitsdangerous==1.1.0\njanome==0.4.1\njax==0.1.62\njaxlib==0.1.41\njdcal==1.4.1\njedi==0.15.2\njeepney==0.4.3\njieba==0.42.1\njinja2-time==0.2.0\njinja2==2.11.2\njmespath==0.10.0\njoblib==0.14.1\njson5==0.9.0\njsonnet==0.16.0\njsonpickle==1.4.1\njsonschema==3.2.0\njupyter-aihub-deploy-extension==0.1\njupyter-client==6.1.3\njupyter-console==6.1.0\njupyter-core==4.6.3\njupyter-http-over-ws==0.0.8\njupyter==1.0.0\njupyterlab-git==0.10.0\njupyterlab-server==1.1.1\njupyterlab==1.2.10\nkaggle-environments==1.6.0\nkaggle==1.5.9\nkeras-preprocessing==1.1.2\nkeras-tuner==1.0.1\nkeras==2.4.3\nkeyring==21.1.1\nkiwisolver==1.2.0\nkmapper==1.4.1\nkmeans-smote==0.1.2\nkmodes==0.10.2\nknnimpute==0.1.0\nkorean-lunar-calendar==0.2.1\nkornia==0.4.1\nkubernetes==10.1.0\nlangid==1.1.6\nlasagne==0.2.dev1\nlazy-object-proxy==1.4.3\nlearntools==0.3.4\nleven==1.0.4\nlibarchive-c==2.9\nlibrosa==0.8.0\nlief==0.9.0\nlightfm==1.15\nlightgbm==2.3.1\nlime==0.2.0.1\nline-profiler==3.1.0\nllvmlite==0.31.0\nlml==0.1.0\nlocket==0.2.0\nlunarcalendar==0.0.9\nlxml==4.5.0\nmako==1.1.3\nmapclassify==2.3.0\nmarisa-trie==0.7.5\nmarkdown==3.2.1\nmarkovify==0.8.3\nmarkupsafe==1.1.1\nmatplotlib-venn==0.11.6\nmatplotlib==3.2.1\nmccabe==0.6.1\nmemory-profiler==0.58.0\nmercantile==1.1.6\nmissingno==0.4.2\nmistune==0.8.4\nmizani==0.7.2\nmkl-fft==1.1.0\nmkl-random==1.1.0\nmkl-service==2.3.0\nml-metrics==0.1.4\nmlcrate==0.2.0\nmlens==0.2.3\nmlxtend==0.17.3\nmmh3==2.5.1\nmne==0.21.2\nmnist==0.2.2\nmock==3.0.5\nmore-itertools==8.2.0\nmpld3==0.5.1\nmplleaflet==0.0.5\nmpmath==1.1.0\nmsgpack-numpy==0.4.7.1\nmsgpack==1.0.0\nmultidict==5.0.2\nmultipledispatch==0.6.0\nmultiprocess==0.70.11.1\nmunch==2.5.0\nmurmurhash==1.0.4\nmxnet-cu102==1.7.0\nmypy-extensions==0.4.3\nnb-conda-kernels==2.2.3\nnb-conda==2.2.1\nnbclient==0.2.0\nnbconvert==5.6.1\nnbdime==2.0.0\nnbformat==5.0.6\nnbpresent==3.0.2\nnervananeon==2.6.0\nnest-asyncio==1.3.2\nnetcdf4==1.5.4\nnetworkx==2.4\nnibabel==3.2.0\nnilearn==0.7.0\nnltk==3.2.4\nnnabla-ext-cuda102==1.13.0\nnnabla==1.13.0\nnolearn==0.6.1\nnose==1.3.7\nnotebook-executor==0.2\nnotebook==5.5.0\nnumba==0.49.1\nnumexpr==2.7.1\nnumpy==1.18.5\nnumpydoc==0.9.2\nnvidia-ml-py3==7.352.0\noauth2client==4.1.3\noauthlib==3.0.1\nodfpy==1.4.1\nolefile==0.46\nonnx==1.8.0\nopencensus-context==0.1.2\nopencensus==0.7.11\nopencv-python-headless==4.4.0.46\nopencv-python==4.4.0.46\nopenpyxl==3.0.3\nopenslide-python==1.1.1\nopt-einsum==3.3.0\noptuna==2.3.0\norderedmultidict==1.0.1\nortools==8.0.8283\nosmnx==0.15.1\nosqp==0.6.1\noverrides==3.1.0\nowslib==0.19.2\npackaging==20.1\npalettable==3.3.0\npandas-datareader==0.9.0\npandas-profiling==2.6.0\npandas-summary==0.0.7\npandas==1.1.4\npandasql==0.7.3\npandoc==1.0.2\npandocfilters==1.4.2\npanel==0.10.1\npapermill==2.1.0\nparam==1.10.0\nparso==0.5.2\npartd==1.1.0\npath.py==12.5.0\npath==13.1.0\npathlib2==2.3.5\npathos==0.2.7\npathspec==0.8.0\npathtools==0.1.2\npatsy==0.5.1\npbr==5.5.1\npdf2image==1.14.0\npdpbox==0.2.0+13.g73c6966\npep8==1.7.1\npexpect==4.8.0\nphik==0.9.11\npickleshare==0.7.5\npillow==8.0.1\npip==20.2.4\npkginfo==1.5.0.1\nplac==1.1.3\nplotly-express==0.4.1\nplotly==4.12.0\nplotnine==0.7.1\npluggy==0.13.0\nply==3.11\npolyglot==16.7.4\npooch==1.2.0\nportalocker==2.0.0\nposix-ipc==1.0.5\npox==0.2.9\npoyo==0.5.0\nppca==0.0.4\nppft==1.6.6.3\npreprocessing==0.1.13\npreshed==3.0.4\nprettytable==0.7.2\nprometheus-client==0.7.1\npromise==2.3\nprompt-toolkit==3.0.5\npronouncing==0.2.0\nprotobuf==3.14.0\npsutil==5.7.0\nptyprocess==0.6.0\npudb==2019.2\npy-cpuinfo==7.0.0\npy-lz4framed==0.14.0\npy-spy==0.3.3\npy-stringmatching==0.4.2\npy-stringsimjoin==0.3.2\npy==1.8.1\npyahocorasick==1.4.0\npyaml==20.4.0\npyarabic==0.6.10\npyarrow==1.0.1\npyasn1-modules==0.2.7\npyasn1==0.4.8\npyastronomy==0.15.2\npybind11==2.6.1\npybrain==0.3\npycairo==1.20.0\npycodestyle==2.5.0\npycosat==0.6.3\npycountry==20.7.3\npycparser==2.20\npycrypto==2.6.1\npyct==0.4.6\npycuda==2020.1\npycurl==7.43.0.5\npydash==4.9.0\npydegensac==0.1.2\npydicom==2.1.1\npydocstyle==5.0.2\npydot==1.4.1\npydub==0.24.1\npyemd==0.5.1\npyepsg==0.4.0\npyexcel-io==0.6.4\npyexcel-ods==0.6.0\npyfasttext==0.4.6\npyflakes==2.1.1\npyglet==1.5.0\npygments==2.6.1\npyjwt==1.7.1\npykalman==0.9.5\npykdtree==1.3.4\npyldavis==2.1.2\npylint==2.4.4\npymc3==3.9.3\npymeeus==0.3.7\npymongo==3.11.0\npympler==0.9\npynvrtc==9.2\npyocr==0.7.2\npyodbc==4.0.30\npyopenssl==19.1.0\npypandoc==1.5\npyparsing==2.4.7\npypdf==1.13\npyperclip==1.8.1\npyprind==2.11.2\npyproj==3.0.0.post1\npyqt5-sip==4.19.18\npyqt5==5.12.3\npyqtwebengine==5.12.1\npyrsistent==0.16.0\npysal==2.1.0\npyshp==2.1.2\npysocks==1.7.1\npystan==2.19.1.1\npytagcloud==0.3.5\npytesseract==0.3.6\npytest-arraydiff==0.3\npytest-astropy-header==0.1.2\npytest-astropy==0.7.0\npytest-cov==2.10.1\npytest-doctestplus==0.4.0\npytest-mock==3.3.1\npytest-openfiles==0.4.0\npytest-remotedata==0.3.1\npytest==5.4.1\npytext-nlp==0.1.2\npython-dateutil==2.8.1\npython-editor==1.0.4\npython-igraph==0.8.2\npython-jsonrpc-server==0.3.4\npython-language-server==0.31.10\npython-levenshtein==0.12.0\npython-louvain==0.14\npython-slugify==4.0.1\npytools==2020.4.3\npytorch-ignite==0.4.2\npytorch-lightning==1.0.6\npytz==2019.3\npyupset==0.1.1.post7\npyviz-comms==0.7.6\npywavelets==1.1.1\npyxdg==0.26\npyyaml==5.3.1\npyzmq==19.0.0\nqdarkstyle==2.8.1\nqgrid==1.3.1\nqtawesome==0.7.1\nqtconsole==4.7.3\nqtpy==1.9.0\nrandomgen==1.16.6\nrasterio==1.1.8\nray==1.0.1\nredis==3.4.1\nregex==2020.4.4\nrequests-oauthlib==1.2.0\nrequests==2.23.0\nresampy==0.2.2\nretrying==1.3.3\nrgf-python==3.9.0\nrmm==0.16.0\nrope==0.16.0\nrsa==4.0\nrtree==0.9.4\nruamel-yaml==0.15.80\ns2sphere==0.2.5\ns3fs==0.5.1\ns3transfer==0.3.3\nsacred==0.8.1\nsacremoses==0.0.43\nscattertext==0.0.2.72\nscikit-image==0.16.2\nscikit-learn==0.23.2\nscikit-multilearn==0.2.0\nscikit-optimize==0.8.1\nscikit-plot==0.3.7\nscikit-surprise==1.1.1\nscipy==1.4.1\nscs==2.1.2\nseaborn==0.10.0\nsecretstorage==3.1.2\nsend2trash==1.5.0\nsentencepiece==0.1.94\nsentry-sdk==0.19.3\nsetuptools-git==1.2\nsetuptools==46.1.3.post20200325\nshap==0.37.0\nshapely==1.7.1\nshortuuid==1.0.1\nsimplegeneric==0.8.1\nsimpleitk==2.0.1\nsimplejson==3.17.0\nsingledispatch==3.4.0.3\nsip==4.19.20\nsix==1.14.0\nsklearn-contrib-py-earth==0.1.0+1.gdde5f89\nsklearn-pandas==2.0.3\nsklearn==0.0\nslicer==0.0.3\nslugify==0.0.1\nsmart-open==3.0.0\nsmhasher==0.150.1\nsmmap==3.0.2\nsnowballstemmer==2.0.0\nsnuggs==1.4.7\nsortedcollections==1.1.2\nsortedcontainers==2.1.0\nsoundfile==0.10.3.post1\nsoupsieve==1.9.4\nspacy==2.3.2\nspectral==0.22.1\nsphinx-rtd-theme==0.2.4\nsphinx==3.0.2\nsphinxcontrib-applehelp==1.0.2\nsphinxcontrib-devhelp==1.0.2\nsphinxcontrib-htmlhelp==1.0.3\nsphinxcontrib-jsmath==1.0.1\nsphinxcontrib-qthelp==1.0.3\nsphinxcontrib-serializinghtml==1.1.4\nsphinxcontrib-websupport==1.2.1\nspyder-kernels==1.9.0\nspyder==4.1.2\nsqlalchemy==1.3.16\nsqlparse==0.3.1\nsquarify==0.4.3\nsrsly==1.0.4\nstatsmodels==0.11.1\nstemming==1.0.1\nstevedore==3.2.2\nstop-words==2018.7.23\nstopit==1.1.2\nsubprocess32==3.5.4\nsvgwrite==1.4\nsympy==1.5.1\ntables==3.6.1\ntabulate==0.8.7\ntangled-up-in-unicode==0.0.4\ntblib==1.6.0\ntenacity==6.1.0\ntensorboard-plugin-wit==1.7.0\ntensorboard==2.4.0\ntensorboardx==2.1\ntensorflow-addons==0.11.2\ntensorflow-cloud==0.1.9\ntensorflow-datasets==3.0.0\ntensorflow-estimator==2.3.0\ntensorflow-gcs-config==2.1.7\ntensorflow-hub==0.10.0\ntensorflow-metadata==0.25.0\ntensorflow-probability==0.11.1\ntensorflow==2.3.1\ntensorforce==0.5.5\ntensorpack==0.10.1\ntermcolor==1.1.0\nterminado==0.8.3\nterminalplot==0.3.0\nterminaltables==3.1.0\ntestpath==0.4.4\ntext-unidecode==1.3\ntextblob==0.15.3\ntexttable==1.6.3\ntextwrap3==0.9.2\ntheano==1.0.5\nthinc==7.4.1\nthreadpoolctl==2.1.0\ntifffile==2020.10.1\ntinycss2==1.1.0\ntokenizers==0.9.2\ntoml==0.10.0\ntoolz==0.10.0\ntorch==1.6.0\ntorchaudio==0.6.0a0+f17ae39\ntorchtext==0.8.0a0+c851c3e\ntorchvision==0.7.0\ntornado==5.0.2\ntpot==0.11.6.post1\ntqdm==4.45.0\ntraitlets==4.3.3\ntraittypes==0.2.1\ntransformers==3.4.0\ntreelite-runtime==0.93\ntreelite==0.93\ntrueskill==0.4.5\ntsfresh==0.17.0\ntyped-ast==1.4.1\ntypeguard==2.10.0\ntyping-extensions==3.7.4.1\ntyping==3.7.4.3\ntzlocal==2.1\nucx-py==0.16.0\nujson==1.35\numap-learn==0.4.6\nunicodecsv==0.14.1\nunidecode==1.1.1\nupdate-checker==0.18.0\nuritemplate==3.0.1\nurllib3==1.25.9\nurwid==2.1.2\nvecstack==0.4.0\nvisions==0.4.1\nvowpalwabbit==8.9.0\nvtk==9.0.1\nwand==0.5.3\nwandb==0.10.10\nwasabi==0.8.0\nwatchdog==0.10.2\nwavio==0.0.4\nwcwidth==0.1.9\nwebencodings==0.5.1\nwebsocket-client==0.57.0\nwerkzeug==1.0.1\nwfdb==3.1.1\nwheel==0.34.2\nwhichcraft==0.6.1\nwidgetsnbextension==3.5.1\nwordbatch==1.4.6\nwordcloud==1.8.1\nwordsegment==1.3.1\nwrapt==1.11.2\nwurlitzer==2.0.0\nxarray==0.16.1\nxgboost==1.2.1\nxlrd==1.2.0\nxlsxwriter==1.2.8\nxlwt==1.3.0\nxvfbwrapper==0.2.9\nyapf==0.29.0\nyarl==1.6.3\nyellowbrick==1.2\nzict==2.0.0\nzipp==3.1.0\n\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# do some proprocessing to make it compatible with the flow_from_directory() method\nraw_data_path = 'data/'\ndata_raw2ImageDataGenerator(raw_data_path)","execution_count":114,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model the training data with simple 2DConvNet from scratch\nmodel_cactus = build_model(raw_data_path)","execution_count":null,"outputs":[{"output_type":"stream","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_6 (Conv2D)            (None, 30, 30, 16)        448       \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 15, 15, 16)        0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 13, 13, 32)        4640      \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 6, 6, 32)          0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 4, 4, 64)          18496     \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 2, 2, 64)          0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 256)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 512)               131584    \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 155,681\nTrainable params: 155,681\nNon-trainable params: 0\n_________________________________________________________________\nNone\nFound 14001 images belonging to 2 classes.\nFound 3499 images belonging to 2 classes.\nEpoch 1/100\n20/20 [==============================] - 5s 233ms/step - loss: 0.5046 - accuracy: 0.7477 - val_loss: 0.4424 - val_accuracy: 0.7547\nEpoch 2/100\n20/20 [==============================] - 5s 234ms/step - loss: 0.3954 - accuracy: 0.8121 - val_loss: 0.4105 - val_accuracy: 0.9098\nEpoch 3/100\n20/20 [==============================] - 4s 217ms/step - loss: 0.3602 - accuracy: 0.8609 - val_loss: 0.3700 - val_accuracy: 0.8547\nEpoch 4/100\n20/20 [==============================] - 4s 220ms/step - loss: 0.3325 - accuracy: 0.8840 - val_loss: 0.2860 - val_accuracy: 0.9020\nEpoch 5/100\n20/20 [==============================] - 4s 209ms/step - loss: 0.3416 - accuracy: 0.8629 - val_loss: 0.2649 - val_accuracy: 0.9156\nEpoch 6/100\n20/20 [==============================] - 5s 247ms/step - loss: 0.2702 - accuracy: 0.9090 - val_loss: 0.2521 - val_accuracy: 0.9180\nEpoch 7/100\n20/20 [==============================] - 4s 207ms/step - loss: 0.2674 - accuracy: 0.9027 - val_loss: 0.2812 - val_accuracy: 0.8977\nEpoch 8/100\n20/20 [==============================] - 4s 219ms/step - loss: 0.2741 - accuracy: 0.8922 - val_loss: 0.2566 - val_accuracy: 0.9133\nEpoch 9/100\n20/20 [==============================] - 5s 230ms/step - loss: 0.2757 - accuracy: 0.8996 - val_loss: 0.2143 - val_accuracy: 0.9258\nEpoch 10/100\n20/20 [==============================] - 4s 203ms/step - loss: 0.2455 - accuracy: 0.9117 - val_loss: 0.2246 - val_accuracy: 0.9121\nEpoch 11/100\n20/20 [==============================] - 4s 216ms/step - loss: 0.2430 - accuracy: 0.9117 - val_loss: 0.2102 - val_accuracy: 0.9270\nEpoch 12/100\n20/20 [==============================] - 4s 204ms/step - loss: 0.2291 - accuracy: 0.9156 - val_loss: 0.2574 - val_accuracy: 0.8977\nEpoch 13/100\n20/20 [==============================] - 4s 202ms/step - loss: 0.2713 - accuracy: 0.8879 - val_loss: 0.2022 - val_accuracy: 0.9324\nEpoch 14/100\n20/20 [==============================] - 5s 247ms/step - loss: 0.2001 - accuracy: 0.9242 - val_loss: 0.2167 - val_accuracy: 0.9184\nEpoch 15/100\n20/20 [==============================] - 4s 195ms/step - loss: 0.2012 - accuracy: 0.9206 - val_loss: 0.2090 - val_accuracy: 0.9176\nEpoch 16/100\n20/20 [==============================] - 4s 212ms/step - loss: 0.2388 - accuracy: 0.9109 - val_loss: 0.2071 - val_accuracy: 0.9145\nEpoch 17/100\n20/20 [==============================] - 4s 198ms/step - loss: 0.2124 - accuracy: 0.9187 - val_loss: 0.1613 - val_accuracy: 0.9363\nEpoch 18/100\n20/20 [==============================] - 4s 197ms/step - loss: 0.1911 - accuracy: 0.9316 - val_loss: 0.1840 - val_accuracy: 0.9312\nEpoch 19/100\n20/20 [==============================] - 4s 214ms/step - loss: 0.2015 - accuracy: 0.9227 - val_loss: 0.1659 - val_accuracy: 0.9422\nEpoch 20/100\n20/20 [==============================] - 4s 199ms/step - loss: 0.2033 - accuracy: 0.9227 - val_loss: 0.1636 - val_accuracy: 0.9371\nEpoch 21/100\n20/20 [==============================] - 5s 230ms/step - loss: 0.1952 - accuracy: 0.9242 - val_loss: 0.1571 - val_accuracy: 0.9383\nEpoch 22/100\n20/20 [==============================] - 5s 231ms/step - loss: 0.2006 - accuracy: 0.9234 - val_loss: 0.2329 - val_accuracy: 0.9082\nEpoch 23/100\n20/20 [==============================] - 4s 212ms/step - loss: 0.1752 - accuracy: 0.9336 - val_loss: 0.1547 - val_accuracy: 0.9395\nEpoch 24/100\n20/20 [==============================] - 4s 211ms/step - loss: 0.2168 - accuracy: 0.9109 - val_loss: 0.1774 - val_accuracy: 0.9348\nEpoch 25/100\n20/20 [==============================] - 4s 195ms/step - loss: 0.1633 - accuracy: 0.9309 - val_loss: 0.1957 - val_accuracy: 0.9340\nEpoch 26/100\n20/20 [==============================] - 4s 197ms/step - loss: 0.1592 - accuracy: 0.9402 - val_loss: 0.2446 - val_accuracy: 0.9102\nEpoch 27/100\n20/20 [==============================] - 4s 209ms/step - loss: 0.1840 - accuracy: 0.9262 - val_loss: 0.1668 - val_accuracy: 0.9391\nEpoch 28/100\n20/20 [==============================] - 4s 194ms/step - loss: 0.1575 - accuracy: 0.9375 - val_loss: 0.2285 - val_accuracy: 0.9145\nEpoch 29/100\n20/20 [==============================] - 5s 226ms/step - loss: 0.1811 - accuracy: 0.9279 - val_loss: 0.1645 - val_accuracy: 0.9254\nEpoch 30/100\n20/20 [==============================] - 4s 195ms/step - loss: 0.1830 - accuracy: 0.9375 - val_loss: 0.1425 - val_accuracy: 0.9488\nEpoch 31/100\n20/20 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.9477","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"It you look at the images found, it should correspond to the specified train/validation split. Look at the number of found classes and make sure it's correct. If not, you probably set up your directory structure incorrectly."},{"metadata":{"trusted":true},"cell_type":"code","source":"# get model results    \nprobabilities = test_model(raw_data_path, model_cactus)","execution_count":90,"outputs":[{"output_type":"stream","text":"/kaggle/working/data/test\n/kaggle/working\nFound 0 images belonging to 0 classes.\n","name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"Asked to retrieve element 0, but the Sequence has length 0","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-90-9f82a997ec7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cactus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-66-4f53fe156a0c>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(data_root_path, model)\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                       shuffle=False)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1881\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m   \u001b[0;31m######################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1577\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m   def _handle_multiprocessing(self, x, workers, use_multiprocessing,\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     55\u001b[0m                              \u001b[0;34m'but the Sequence '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                              'has length {length}'.format(idx=idx,\n\u001b[0;32m---> 57\u001b[0;31m                                                           length=len(self)))\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_batches_seen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Asked to retrieve element 0, but the Sequence has length 0"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# write model results in the format required by the Kaggle competition.\nwrite_submission(raw_data_path, probabilities)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}